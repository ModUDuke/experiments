--- 
title       : "Experiments 7: Noncompliance"
description : "These videos and exercises discuss the issue of noncompliance in experiments."

--- type:VideoExercise lang:r aspect_ratio:62.5 xp:50 skills:1 key:a5a7d9f747
## Noncompliance in Experiments
*** =video_link
//player.vimeo.com/video/198212091

--- type:MultipleChoiceExercise lang:r xp:50 skills:1 key:c896674673
## Ways to Deal with Noncompliance
Which one of the following approaches is *not* a way to deal with treatment noncompliance?

*** =instructions
- Bounds Analysis
- Instrumental Variables
- Randomized Control Trial
- Intention to Treat Analysis
- Assume Random Compliance

*** =sct
```{r}
msg1 = "Bounds Analysis is definitely a common method used to deal with noncompliance, and we're looking for a way that is **not** appropriate, so try again."
msg2 = "Instrumental variables is definitely a common method used to deal with noncompliance, and we're looking for a way that is **not** appropriate, so try again."
msg3 = "Correct! Randomized Control Trials are not a valid way to correct for noncompliance, because they themselves are susceptible to treatment noncompliance."
msg4 = "Intention to Treat Analysis is definitely a common way to deal with noncompliance, and we're looking for a way that is **not** appropriate, so try again"
msg5 = "Assuming Random Compliance is not always applicable, but it is nonetheless commonly used to deal with noncompliance, so try again"
test_mc(correct = 3, feedback_msgs = c(msg1,msg2,msg3,msg4,msg5))
```

--- type:MultipleChoiceExercise lang:r xp:50 skills:1 key:84487e1a9f
## A Refresher on eGulf Auctions Experiment and Confidence Intervals 
Let's go back to our experiment with eGulf, the popular online auctioneer. In a previous exercise, we found that sellers on eGulf who posted more than 10 pictures of their WePhones during auctions (the treatment group) had higher sales prices than sellers who only posted 10 pictures of their WePhones (the control group). eGulf wanted to make sure these results were not spurious by conducting their experiment a second time, with a larger sample. The results of this second experiment were visualized as a bar graph, with 95% confidence intervals indicated by error bars. Based on these results, shown in the R workspace, what can we conclude about the average treatment effect (ATE)? 

*** =instructions
- The ATE is not statistically significant at a 95% confidence interval.
- The ATE is not statistically significant at a 99% confidence interval.
- The ATE is statistically significant at a 95% confidence interval.
- The ATE is statistically significant at a 99% confidence interval.
*** =pre_exercise_code
```{r}
library(data.table)
library(dplyr)
# Initialize dataframe
set.seed(1)
n <- 1000
eGulf <- as.data.frame(matrix(0, ncol=5,nrow=n))
colnames(eGulf) <- c("Seller_Offered_Treatment","Seller_Opted_Into_Treatment","Seller_Feedback_Count","Seller_Feedback_Score","Auction_Final_Sales_Price")
# Simulate baseline data
  # Make seller feedback count
    eGulf$Seller_Feedback_Count<-as.integer(abs(round(rnorm(n,200,100))))
  # Make feedback score loosely correlated with feedback count 
    eGulf$Seller_Feedback_Score<-round(.9+.1*eGulf$Seller_Feedback_Count/max(eGulf$Seller_Feedback_Count)-rbeta(100,1,10),2)
  # Make seller offered treatment loosely correlated with with feedback count 
    eGulf$Seller_Offered_Treatment<-rbinom(n,1,.5+eGulf$Seller_Feedback_Count/max(eGulf$Seller_Feedback_Count)/5)
  # Make seller opted_into_treatment correlated with seller_feedback_score
    eGulf$Seller_Opted_Into_Treatment<-ifelse(eGulf$Seller_Offered_Treatment==0,0,rbinom(n,1,eGulf$Seller_Feedback_Score^5)) #
  # Make final sales price also correlated with seller_feedback_score
    eGulf$Final_Sales_Price<-round(rlnorm(n, meanlog=log(400), sdlog = log(1.2))*eGulf$Seller_Feedback_Score)

    
#Prepare data for graphing
  TreatmentSalesPrices<-eGulf$Final_Sales_Price[eGulf$Seller_Opted_Into_Treatment==1]
  ControlSalesPrices<-eGulf$Final_Sales_Price[eGulf$Seller_Opted_Into_Treatment==0]
  TreatmentMean<-mean(TreatmentSalesPrices)
  ControlMean<-mean(ControlSalesPrices)
  TreatmentStandardError<-sd(TreatmentSalesPrices)/sqrt(length(TreatmentSalesPrices))
  ControlStandardError<-sd(ControlSalesPrices)/sqrt(length(ControlSalesPrices))
  Means<-c(ControlMean,TreatmentMean)
  names(Means)<-c("Control Mean","Treatment Mean")
  CIs<-c(ControlStandardError,TreatmentStandardError)

#Graph results
  #(cheat to pretend this is a different sample; just use the standard errors rather than true confidence intervals. This makes the differences clearly visible.)
  arrows(x0=barplot(Means,ylim=c(325, 375),col=c(3,5)), y0=Means-(1*CIs), y1=Means+(1*CIs), code=3, angle=90,length=.4)

```

*** =sct
```{r}
msg1 = "Do the error bars overlap? Look carefully at the graph and try again."
msg2 = "The graph does not show error bars for the 99% confidence interval, so no conclusion can be made about the statistical significance of the ATE at the 99% confidence interval. Try again."
msg3 = "Correct! Since the 95% confidence interval error bars do not appear to overlap, we can conclude that the difference is statistically significant."
msg4 = "The graph does not show error bars for the 99% confidence interval, so no conclusion can be made about the statistical significance of the ATE at the 99% confidence interval. Try again."
test_mc(correct = 3, feedback_msgs = c(msg1,msg2,msg3,msg4))
```

---
## Let's Code: Noncompliance in eGulf Data
```yaml
type: VideoExercise
lang: r
xp: 50
skills: 1
key: f309deee16
video_link: "//player.vimeo.com/video/279737646"
```

--- type:NormalExercise lang:r aspect_ratio:62.5 xp:50 skills:1 key:ac78544021
## eGulf Auctions Experiment: Noncompliance
In a previous exercise, we found that sellers on eGulf who posted more than 10 pictures of their WePhones during auctions had higher sales prices. However, we never examined whether noncompliance could have confounded our results. Specifically, what if the sellers who chose to post more than 10 pictures of their WePhones were different from those who chose not to post more than 10 pictures? 

If the experiment's dependent variable is associated with a difference between compliers and noncompliers, its association with the treatment effect may be spurious. Therefore, we should test whether compliance was associated with any traits among the sellers, and whether such traits were associated with final sales prices. With the dataset `eGulf`:

*** =instructions
- 1) Test whether sellers who were offered treatment (`Seller_Offered_Treatment`) and opted into the treatment (`Seller_Opted_Into_Treatment`==1) had different prior average feedback scores (`Seller_Feedback_Score`) than sellers who were offered treatment but did not opt into treatment. 
- 2) Test whether sellers' prior average feedback scores (`Seller_Feedback_Score`) were associated with their recent auction's final sales price (`Final_Sales_Price`).

*** =hint
- For the first question, you will need to `subset` the `eGulf` data frame by whether they were offered treatment `and` by whether they opted in. 
- It may help to create a new dataframe called `CompliantTreatmentGroup` that contains only sellers who were offered and opted into treatment, and a new data frame called `NoncompliantTreatmentGroup` who were offered but did not opt into treatment.
- Use the `t.test` function where (mu=0) to statistically test whether the treatment and control group are different from each other.

*** =pre_exercise_code
```{r}
library(data.table)
library(dplyr)

# Initialize dataframe
set.seed(1)
n <- 1000
eGulf <- as.data.frame(matrix(0, ncol=5,nrow=n))
colnames(eGulf) <- c("Seller_Offered_Treatment","Seller_Opted_Into_Treatment","Seller_Feedback_Count","Seller_Feedback_Score","Auction_Final_Sales_Price")
# Simulate baseline data
  # Make seller feedback count
    eGulf$Seller_Feedback_Count<-as.integer(abs(round(rnorm(n,200,100))))
  # Make feedback score loosely correlated with feedback count 
    eGulf$Seller_Feedback_Score<-round(.9+.1*eGulf$Seller_Feedback_Count/max(eGulf$Seller_Feedback_Count)-rbeta(100,1,10),2)
  # Make seller offered treatment loosely correlated with with feedback count 
    eGulf$Seller_Offered_Treatment<-rbinom(n,1,.5+eGulf$Seller_Feedback_Count/max(eGulf$Seller_Feedback_Count)/5)
  # Make seller opted_into_treatment correlated with seller_feedback_score
    eGulf$Seller_Opted_Into_Treatment<-ifelse(eGulf$Seller_Offered_Treatment==0,0,rbinom(n,1,eGulf$Seller_Feedback_Score^5)) #
  # Make final sales price also correlated with seller_feedback_score
    eGulf$Final_Sales_Price<-round(rlnorm(n, meanlog=log(400), sdlog = log(1.2))*eGulf$Seller_Feedback_Score)
```
*** =sample_code
```{r}
# 1) To check for noncompliance in an experiment, we will only want to compare individuals that were offered treatment. Therefore, it might make the problems below easier if you first subset the eGulf data.frame to sellers who were offered treatment. However, we will leave that choice up to you. 

# 2) Before running a significance test to see whether egulf compliers and noncompliers were different, let's summarize the data.
    summary(eGulf$Seller_Feedback_Score[eGulf$Seller_Opted_Into_Treatment==0 & eGulf$Seller_Offered_Treatment==1])
    summary(eGulf$Seller_Feedback_Score[eGulf$Seller_Opted_Into_Treatment==1 & eGulf$Seller_Offered_Treatment==1])

# 3) It appears that those who opted into the treatment have slightly higher feedback scores than those who did not, but is the difference statistically significant? Fill in the t-test syntax below to measure the confidence interval of the mean difference between those who were offered treatment and opted into the treatment and those who were offered treatment but did not opt into treatment.
#---- Question 1-------------------------------------#
    t.test()$conf.int
#----------------------------------------------------#
    
# 4) The confidence interval indicates a range of values for the average treatment effect that we would expect to find if we gathered a new sample. If the lower and upper bound of the 95% confidence interval are both positive, we can conclude that there is a positive and statistically significant difference between the two groups. Based on the results from your t-test above, does it appear that those who opted into treatment had seller feedback scores that were significantly higher than those who did not opt into treatment? Answer with "Yes" or "No."
#---- Question 2-------------------------------------#
    Solution2<- ""
#----------------------------------------------------#

# 5) For a fuller understanding of the potential bias produced by noncompliance, let's examine the relationship between opting into treatment and feedback scores in a different way. Estimate the correlation between seller feedback scores and final sales prices.
#---- Question 3-------------------------------------#
    Solution3<- ""
#----------------------------------------------------#

```
*** =solution
```{r}
Significant<-all(t.test(eGulf$Seller_Feedback_Score[eGulf$Seller_Opted_Into_Treatment==1&eGulf$Seller_Offered_Treatment==1],eGulf$Seller_Feedback_Score[eGulf$Seller_Opted_Into_Treatment==0 & eGulf$Seller_Offered_Treatment==1])$conf.int>0)

Solution2<-ifelse(Significant==T,"Yes","No")
Solution3<-cor(eGulf$Seller_Feedback_Score,eGulf$Final_Sales_Price)
```
*** =sct
```{r}
test_object("Solution2")
test_object("Solution3")
success_msg("Good work! It looks like sellers who posted more photos tended to have higher prior average feedback scores than those who did not post more photos. Additionally, prior average feedback scores were positively correlated with final WePhone sales prices. Since compliers and non-compliers have different feedback scores, and feedback scores are associated with final sales prices, the experiment's results might be spurious. While the experiment had intended to estimate whether posting more photos caused sellers to attain higher sales prices, the experiment might have just shown that sellers who care about customer feedback tend to sell their goods at high prices, and would be willing to post more photos on their ebay auctions if they were given the chance.")
```


--- type:VideoExercise lang:r aspect_ratio:62.5 xp:50 skills:1 key:db0bf3e371
## Survey Noncompliance
*** =video_link
//player.vimeo.com/video/198212102


--- type:MultipleChoiceExercise lang:r xp:50 skills:1 key:1557ba9536
## Offering a Higher Credit Card Limit: Quantifying Noncompliance Concerns
CreditCo, a large credit card company, decides to run an experiment. It sends an offer in the mail to a random group of 50% of its customers: those in the treatment group are invited to navigate to a webpage and opt in for a 10% higher credit limit. CreditCo wants to see how credit balances and late payments are impacted six months later as a result of the experiment. 

Suppose that, of the group that received the mail offer, 40% of people opted in. Do you think that noncompliance will be a problem for CreditCo's analysis? Why or why not?

*** =instructions
- No, because people in the treatment group likely used a coin flip to make their opt-in decision.
- Yes, because the opt-in rate is low.
- No, because an opt-in rate of 40% is actually quite high.
- Yes, because the set of people opting in are probably people with worse spending habits.

*** =sct
```{r}
msg1 = "While this is a possibility, it is unlikely to actually be the case. Try again."
msg2 = "This is partially correct. A low compliance rate is one symptom of a noncompliance problem."
msg3 = "While high compliance rates indicate a lower noncompliance problem, the rate of 40% in this situation is likely to be problematic."
msg4 = "Correct! In this situation, researchers at CreditCo should be worried about the spending habits of those who opted in to the offer."
test_mc(correct = 4, feedback_msgs = c(msg1,msg2,msg3,msg4))
```

--- key:f6472f88d4
## Let's Code: Working with Noncompliance
```yaml
type: VideoExercise
lang: r
xp: 50
skills: 1
key: 
video_link: //player.vimeo.com/video/279737627
```

--- type:NormalExercise lang:r xp:100 skills:1 key:a00d1ebc4c
## Offering a Higher Credit Card Limit: Working with Noncompliance
Let's continue with the CreditCo dataset described in the previous exercise. The CFO has assigned you to figure out the average treatment effect of taking a credit line increase offer on late payments (defaults), and he wants to see something before lunch. You realize that you can give him a simple result: you just need to do some quick checks for balance in your samples and compute a "naive" average treatment effect to get the analysis started.

A simulated version of this dataset, `CreditCo`, is available in the workspace.  With that data:

*** =instructions
- 1) See if treatment and control groups are of equal size.
- 2) Compute the fraction of people who opted in to the credit offer.
- 3) Compute a naive average treatment effect.
- The treatment variable is a column in `CreditCo` called `offered.`
- The opt-in variable is a column called `opt_in.` 
- The late-payment variable is called `default_post.`

*** =hint
- Remember to select the appropriate sample when computing the opt-in rate of the credit offer.


*** =pre_exercise_code
```{r}
library(data.table)
library(dplyr)

  set.seed(1)
  n             <- 9e5
  frac_treated  <- .5
  frac_female   <- .5656
  frac_white    <- .688

# Initialize dataframe
  CreditCo <- as.data.frame(matrix(0, ncol=11,nrow=n))
  colnames(CreditCo) <- c("id","offered","opt_in","FICO","age","female","race_white","default_pre","default_post","balance_pre","balance_post")

# Simulate baseline data
  CreditCo$id         <- seq(1,n,1)
  CreditCo$offered    <- as.integer(runif(n)<frac_treated)
  CreditCo$opt_in     <- rep.int(0,n)
  CreditCo$FICO       <- rnorm(n, mean=736, sd=300)
  CreditCo$age        <- sample(18:55, n, replace=T)
  CreditCo$female     <- as.integer(runif(n)<frac_female)
  CreditCo$race_white <- as.integer(runif(n)<frac_white)

# make FICO score intelligible
  CreditCo$FICO[CreditCo$FICO>850] <- 850
  CreditCo$FICO[CreditCo$FICO<300] <- 300
  CreditCo$FICO                    <- round(CreditCo$FICO)

# simulate pre-experiment default rate
  draw <- runif(n)
  xb   <- -1.82-0.2*CreditCo$FICO/100+.046*(CreditCo$FICO^2)/10000-5.1*CreditCo$female-7*CreditCo$race_white
  p    <- exp(xb)/(1+exp(xb))
  CreditCo$default_pre <- as.integer(draw<p)

# simulate pre-experiment balance level
  draw <- rnorm(n, mean=0, sd=0.5)
  CreditCo$balance_pre <- 8.5-0.2*CreditCo$FICO/100+.046*(CreditCo$FICO^2)/10000-0.15*CreditCo$female-0.85*CreditCo$race_white + draw
  CreditCo$balance_pre <- exp(CreditCo$balance_pre)

# Simulate noncompliance and opt-in behavior
  draw <- runif(sum(CreditCo$offered))
  xb   <- 6.75-1.2*CreditCo$FICO/100+.07*(CreditCo$FICO^2)/10000-2.1*CreditCo$female-2*CreditCo$race_white
  p    <- exp(xb)/(1+exp(xb))
  CreditCo$opt_in[CreditCo$offered==1] <- as.integer(draw<p[CreditCo$offered==1])

# Simulate post outcomes
  draw <- runif(n)
  xb   <- -1.82-0.2*CreditCo$FICO/100+.046*(CreditCo$FICO^2)/10000-5.1*CreditCo$female-7*CreditCo$race_white+4*CreditCo$offered*CreditCo$opt_in
  p    <- exp(xb)/(1+exp(xb))
  CreditCo$default_post <- as.integer(draw<p)

# balance
  draw <- rnorm(n, mean=0, sd=0.5)
  CreditCo$balance_post <- 8.5-0.2*CreditCo$FICO/100+.046*(CreditCo$FICO^2)/10000-0.15*CreditCo$female-0.85*CreditCo$race_white + 1*CreditCo$offered*CreditCo$opt_in + draw
  CreditCo$balance_post <- exp(CreditCo$balance_post)

# Remove elements and variables from environment
  rm(draw,frac_female,frac_treated,frac_white,n,p,xb)
  CreditCo <- CreditCo[,c("id","offered","opt_in","FICO","female","race_white","default_pre","default_post","balance_pre","balance_post")]
```

*** =sample_code
```{r}
# The dataset `CreditCo` is available in your workspace. You may want to explore it with the structure "str" command before solving the following questions.

# Question 1: Compute the fraction of people who were offered a higher credit limit
#---- Question 1-------------------------------------#
    Solution1<- 
#----------------------------------------------------#

# Question 2: Of the people who were offered, what fraction opted in?
#---- Question 2-------------------------------------#
    Solution2<- 
#----------------------------------------------------#

# Question 3: Compute a naive average treatment effect of late payment (variable `default_post`), where treatment state is defined by having been offered **and** opted in to the program
#---- Question 3-------------------------------------#
    Solution3<- 
#----------------------------------------------------#

```

*** =solution
```{r}
Solution1<-mean(CreditCo$offered)
Solution2<-mean(CreditCo$opt_in[CreditCo$offered==1])
Solution3<-mean(CreditCo$default_post[CreditCo$opt_in==1])-mean(CreditCo$default_post[CreditCo$offered==0])
```

*** =sct
```{r}
test_object("Solution1")
test_object("Solution2")
test_object("Solution3")
success_msg("Nice job! As you can see, about half of the sample received an offer, but only about 41% of people actually accepted it. For the people who complied, the 'naive' treatment effect is a +26% default rate--the default rate went up for people who accepted the offer! However, while this 'naive' ATE is quick to calculate, it's probably not accurate, as there are likely confounders that we can deal with when we have more time.")
```
