--- 
title       : "Experiments 10: Bounds Analysis"
description : "These videos and a related exercise discuss how to form bounds on causal effects in the presence of experimental noncompliance."


--- type:VideoExercise lang:r aspect_ratio:62.5 xp:50 skills:1 key:25526ab294
## Bounds Analysis for Missing Data
*** =video_link
//player.vimeo.com/video/199858153

---
## Let's Code: Computing Bounds Under Noncompliance
```yaml
type: VideoExercise
lang: r
xp: 50
skills: 1
key: 06215f9d20
video_link: "//player.vimeo.com/video/279737481"
```


--- type:NormalExercise lang:r xp:100 skills:1 key:a42175703d
## Offering a Higher Credit Card Limit: Computing Bounds Under Noncompliance
Your first calculations on the CreditCo data in Chapter 7 showed that noncompliance was an issue in the experiment. In the previous chapter, you examined how to resolve this issue using a natural experiment. This time, we have provided you with more data to examine, particularly the credit ratings for the individuals in both the treatment and control groups. But goal remains the same as before: does the offer of a higher credit limit decrease the number of late payments (defaults)? 

Let's try a different approach in this exercise. Specifically, compute the bounds of the average treatment effect of opting into a credit line offer. This question is tricky. To accomplish this task, you may want to refer to the video at the beginning of the chapter.

*** =instructions
- 1) Determine the ratio of people who accepted the offer.
- 2) Compute upper bound on the average treatment effect under non-compliant behavior.
- 3) Compute lower bound on the average treatment effect under non-compliant behavior.
- Bonus: Compare this with the results of an intention-to-treat analysis, under random compliance, or both!

*** =hint
- When the values of a variable are binary (0 or 1), you can calculate the proportion of 1s by simply taking the mean of the variable.
- Remember to be aware of selecting the correct subsample.

*** =pre_exercise_code
```{r}

library(data.table)
library(dplyr)
  set.seed(1)
  n             <- 9e3
  frac_treated  <- .5
  frac_female   <- .5656
  frac_white    <- .688

# Initialize dataframe
  CreditCo <- as.data.frame(matrix(0, ncol=11,nrow=n))
  colnames(CreditCo) <- c("id","offered","opt_in","FICO","age","female","race_white","default_pre","default_post","balance_pre","balance_post")

# Simulate baseline data
  CreditCo$id         <- seq(1,n,1)
  CreditCo$offered    <- as.integer(runif(n)<frac_treated)
  CreditCo$opt_in     <- rep.int(0,n)
  CreditCo$FICO       <- rnorm(n, mean=736, sd=300)
  CreditCo$age        <- sample(18:55, n, replace=T)
  CreditCo$female     <- as.integer(runif(n)<frac_female)
  CreditCo$race_white <- as.integer(runif(n)<frac_white)

# make FICO score intelligible
  CreditCo$FICO[CreditCo$FICO>850] <- 850
  CreditCo$FICO[CreditCo$FICO<300] <- 300
  CreditCo$FICO                    <- round(CreditCo$FICO)

# simulate pre-experiment default rate
  draw <- runif(n)
  xb   <- -1.82-0.2*CreditCo$FICO/100+.046*(CreditCo$FICO^2)/10000-5.1*CreditCo$female-7*CreditCo$race_white
  p    <- exp(xb)/(1+exp(xb))
  CreditCo$default_pre <- as.integer(draw<p)

# simulate pre-experiment balance level
  draw <- rnorm(n, mean=0, sd=0.5)
  CreditCo$balance_pre <- 8.5-0.2*CreditCo$FICO/100+.046*(CreditCo$FICO^2)/10000-0.15*CreditCo$female-0.85*CreditCo$race_white + draw
  CreditCo$balance_pre <- exp(CreditCo$balance_pre)

# Simulate noncompliance and opt-in behavior
  draw <- runif(sum(CreditCo$offered))
  xb   <- 6.75-1.2*CreditCo$FICO/100+.07*(CreditCo$FICO^2)/10000-2.1*CreditCo$female-2*CreditCo$race_white
  p    <- exp(xb)/(1+exp(xb))
  CreditCo$opt_in[CreditCo$offered==1] <- as.integer(draw<p[CreditCo$offered==1])

# Simulate post outcomes
  draw <- runif(n)
  xb   <- -1.82-0.2*CreditCo$FICO/100+.046*(CreditCo$FICO^2)/10000-5.1*CreditCo$female-7*CreditCo$race_white+4*CreditCo$offered*CreditCo$opt_in
  p    <- exp(xb)/(1+exp(xb))
  CreditCo$default_post <- as.integer(draw<p)

# balance
  draw <- rnorm(n, mean=0, sd=0.5)
  CreditCo$balance_post <- 8.5-0.2*CreditCo$FICO/100+.046*(CreditCo$FICO^2)/10000-0.15*CreditCo$female-0.85*CreditCo$race_white + 1*CreditCo$offered*CreditCo$opt_in + draw
  CreditCo$balance_post <- exp(CreditCo$balance_post)

# Remove elements and variables from environment
  rm(draw,frac_female,frac_treated,frac_white,n,p,xb)
  CreditCo <- CreditCo[,c("id","offered","opt_in","FICO","female","race_white","default_pre","default_post","balance_pre","balance_post")]
```

*** =sample_code
```{r}

# 1) Determine the ratio of people who accepted the offer and assign this to Solution1
    Solution1<-mean()

# 2) Compute upper bound on the average treatment effect under non-compliant behavior and assign this to Solution2.


# 3) Compute lower bound on the average treatment effect under non-compliant behavior and assign this to Solution3.


```

*** =solution
```{r}
Solution1 <- mean(CreditCo$opt_in[CreditCo$offered==1])
Solution2 <- Solution1*mean(CreditCo$default_post[CreditCo$opt_in==1]) + (1-Solution1)*1 - mean(CreditCo$default_post[CreditCo$offered==0])
Solution3 <- Solution1*mean(CreditCo$default_post[CreditCo$opt_in==1]) + (1-Solution1)*0 - mean(CreditCo$default_post[CreditCo$offered==0])

```

*** =sct
```{r}
test_object("Solution1")
test_object("Solution2")
test_object("Solution3")

success_msg("Nice job! As you can see, we get slightly different answers based on the method we use. What did we learn from this experiment overall? Well, that depended on the technique you used to analyze it. When working with data, usually the best option is to learn the answers from multiple techniques so that you can have a more complete and nuanced interpretation of what really happened.")
```

--- type:VideoExercise lang:r aspect_ratio:62.5 xp:50 skills:1 key:0588056e73
## Experimental Design & RCTs
*** =video_link
//player.vimeo.com/video/209271489
